{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Topic Modeling Visualisations<a id='top'></a>\n",
    "\n",
    "This page allows you to browse through topic models generated by [create_lda.ipynb](create_lda.ipynb).\n",
    "\n",
    "Scroll down to see the plots or use these links:\n",
    "\n",
    "* [Estimate number of clusters](#clusters)\n",
    "* [Corpus map](#map)\n",
    "* [Topic intensity](#topic_bubbles)\n",
    "* [Print topics](#print_topics)\n",
    "* [Development of topics over time](#stats_per_topic)\n",
    "* [Topic statistics per blog or profile](#stats_per_blog)\n",
    "* [Data table for corpus / subcorpus / blog or profile](#data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading russian_literature_topics.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'projects/russian_literature/russian_literature_mallet.lda.wordtopics.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-35a2635030a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# load lda model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# model = models.LdaModel.load(os.path.join(result_path, project + \"_mallet.lda\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_mallet.lda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working/generic-topic-modeling/lib64/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \"\"\"\n\u001b[1;32m   1637\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mmap'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mmap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;31m# check if `random_state` attribute has been set after main pickle load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working/generic-topic-modeling/lib64/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working/generic-topic-modeling/lib64/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working/generic-topic-modeling/lib64/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'projects/russian_literature/russian_literature_mallet.lda.wordtopics.npy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.pylabtools import figsize\n",
    "from sklearn.manifold import Isomap\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import qgrid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "import scripts.spin as sp\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim import corpora, models\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import datetime as dt\n",
    "\n",
    "figsize(15, 10)\n",
    "\n",
    "project = \"russian_literature\"\n",
    "result_path = \"projects\" + os.path.sep + project\n",
    "file_name = project +\"_topics.json\"\n",
    "\n",
    "# load topic json\n",
    "print(\"Loading\", file_name)\n",
    "table = pd.read_json(os.path.join(result_path, file_name), orient='split')\n",
    "\n",
    "# load lda model\n",
    "# model = models.LdaModel.load(os.path.join(result_path, project + \"_mallet.lda\"))\n",
    "model = models.LdaModel.load(os.path.join(result_path, project + \"_mallet.lda\"))\n",
    "\n",
    "def percent(x, pos):\n",
    "    return str(int(x * 100)) + \"%\"\n",
    "\n",
    "formatter = FuncFormatter(percent)\n",
    "\n",
    "def corpus_stats(Subcorpus):\n",
    "    sub = table.loc[table['group'].str.contains(Subcorpus)]\n",
    "    # get top topics\n",
    "    weighted = sub['words'] / sub['words'].sum()\n",
    "    sub2 = sub.copy()\n",
    "    sub2[sub2.columns[5:]] = sub2[sub2.columns[5:]].multiply(weighted, axis='index')\n",
    "    top_topics = sub2[sub2.columns[4:]].sum()\n",
    "    new_index = ['url', 'date']\n",
    "    for idx in top_topics.index:\n",
    "        new_index.append(idx)\n",
    "    sub = sub[new_index]\n",
    "    return sub, top_topics\n",
    "    \n",
    "def topic_stats(Topics):\n",
    "    topic_stats = table.copy()\n",
    "    topic_stats.index = pd.to_datetime(topic_stats['date'], format='%Y')\n",
    "    weighted = topic_stats['words'] / topic_stats['words'].sum()\n",
    "    topic_stats[topic_stats.columns[5:]] = topic_stats[topic_stats.columns[5:]].multiply(weighted, axis='index')\n",
    "    \n",
    "    # reduce to topics\n",
    "    for Topic in Topics:\n",
    "        topic_stats[(topic_stats.index.year>1800)][Topic].resample('Y').sum().plot(kind='line', label=Topic)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title = Topics\n",
    "    plt.ylim(0, 0.007)\n",
    "    plt.savefig(str(Topics)+\"_time.png\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot(data, title=\"Isomap\", clrs=None, max_val=0, words=None, labels=None, huep=False):\n",
    "    if clrs is None:\n",
    "        clrs = [0]*len(data)\n",
    "    if labels is None:\n",
    "        labels = [\"\"]*len(data)\n",
    "    if words is None:\n",
    "        words = [250]*len(data)   \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    matplotlib.rcParams.update({'font.size': 12})\n",
    "    plt.title = title\n",
    "    # plt.xlim(-0.3, 0.3)\n",
    "    # plt.ylim(-0.2, 0.2)\n",
    "    ax1.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off')\n",
    "    scatter = ax1.scatter(data.T[0], data.T[1], marker='o', s=words, c=clrs,\n",
    "                          vmin=0, vmax=max_val, cmap=matplotlib.cm.get_cmap('coolwarm'))\n",
    "    for counter in range(len(data)):\n",
    "        label_scale = words[counter]/(70*2500)\n",
    "        plt.annotate(labels[counter], xy=(data[counter][0]+label_scale, data[counter][1]+label_scale))\n",
    "    plt.tight_layout()\n",
    "    if huep:\n",
    "        plt.colorbar(scatter, format=formatter)\n",
    "    plt.savefig(title+\"_bubbles.png\")\n",
    "    plt.show()\n",
    "\n",
    "# create statistics per blog\n",
    "names = table['group'].drop_duplicates()\n",
    "series = []\n",
    "for name in names:\n",
    "    sub, top_topics = corpus_stats(name)\n",
    "    series.append(top_topics)\n",
    "stats_per_blog = pd.concat(series, axis=1).transpose()\n",
    "stats_per_blog.index = names\n",
    "\n",
    "names = ['', 'everyday', 'literary', 'political']\n",
    "names.extend(pd.DataFrame({'count': table.groupby([\"group\"]).size()}).reset_index()['group'])\n",
    "\n",
    "# prepare matrix for isomap / distance matrix\n",
    "topics_per_blog = stats_per_blog.copy()\n",
    "del topics_per_blog['words']\n",
    "matrix = topics_per_blog.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate number of clusters<a id='clusters'></a>\n",
    "\n",
    "Create an elbow plot to estimate a sane number of clusters for the corpus.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(1,11)\n",
    "KM = [KMeans(n_clusters=k).fit(matrix) for k in K]\n",
    "centroids = [k.cluster_centers_ for k in KM]\n",
    "\n",
    "D_k = [cdist(matrix, cent, 'euclidean') for cent in centroids]\n",
    "dist = [np.min(D,axis=1) for D in D_k]\n",
    "avgWithinSS = [sum(d)/matrix.shape[0] for d in dist]\n",
    "\n",
    "# elbow curve\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, avgWithinSS, 'b*-', color='r')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel(u'Within Sum of Squares')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Corpus overview using Isomap<a id='map'></a>\n",
    "\n",
    "In this plot the 37 blogs and social media profiles are represented by their topic distribution. The Isomap algorithm is used to create a two-dimensional map of this high-dimensional topic space. Each dot represents a blog/profile; dots close to each other have a similar topic distribution. Colors indicate groups suggested by K-means clustering.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_corpus(Clusters=4):\n",
    "    # cluster blogs\n",
    "    km = KMeans(n_clusters=Clusters, random_state=5)\n",
    "    clusters = km.fit_predict(matrix)\n",
    "    print(\"Silhouette score:\", silhouette_score(matrix, clusters))\n",
    "\n",
    "    # plot corpus map using Isomap\n",
    "    imap = Isomap()\n",
    "    corpus_map = imap.fit_transform(matrix)\n",
    "    figsize (32, 32)\n",
    "    plot(corpus_map, \"Corpus Map\", labels=table['group'].drop_duplicates().values, clrs=clusters, max_val=Clusters)\n",
    "    figsize (15, 10)\n",
    "\n",
    "interact(plot_corpus, Clusters=range(2,10), );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Plot distance matrix\n",
    "\n",
    "Create a distance matrix showing distances between different blogs or social media profiles.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "distances = pdist(topics_per_blog.values, metric='euclidean')\n",
    "dist_matrix = squareform(distances)\n",
    "figsize (30, 20)\n",
    "\n",
    "#sort blogs with SPIN\n",
    "order = np.array(range(len(dist_matrix[0])))\n",
    "new_distances, new_order = sp.spin(dist_matrix, order)\n",
    "\n",
    "# re-sort ids according to spin\n",
    "new_ids = []\n",
    "for index in new_order:\n",
    "    new_ids.append(stats_per_blog.index[index])\n",
    "\n",
    "dist_matrix = pd.DataFrame(new_distances)\n",
    "dist_matrix.columns = new_ids\n",
    "dist_matrix.index = new_ids\n",
    "\n",
    "mask = np.zeros_like(new_distances)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "seaborn.set_context(\"notebook\", font_scale=0.9)\n",
    "with seaborn.axes_style(\"white\"):\n",
    "    ax = seaborn.heatmap(dist_matrix, mask=mask, square=True, annot=False, fmt='.2f')\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90) \n",
    "plt.show()\n",
    "figsize (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 5,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Plot topic bubbles<a id='topic_bubbles'></a>\n",
    "\n",
    "Again, the Isomap algorithm is used to create a map of the corpus. Use the dropdown box to select a topic; colors indicate intensity of topic, bubble size is total number of words in a blog/profile.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 2,
        "hidden": false,
        "row": 5,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "words = stats_per_blog['words']\n",
    "copy = stats_per_blog.copy()\n",
    "del copy['words']\n",
    "matrix = copy.values\n",
    "\n",
    "# scale dots with blog size\n",
    "max_words = max(words)\n",
    "num = 0\n",
    "while(num < len(words)):\n",
    "    words[num] = 2500*words[num]/max_words\n",
    "    num += 1\n",
    "    \n",
    "def create_bubbles(Topic=41):\n",
    "    # Isomap\n",
    "    imap = Isomap()\n",
    "    X = imap.fit_transform(matrix)\n",
    "    plot(X, list(copy)[Topic], matrix[:, Topic], max(matrix[:, Topic]), words, huep=True)\n",
    "    \n",
    "box = {}\n",
    "counter = 0\n",
    "for label in list(table)[5:]:\n",
    "    box[label] = counter\n",
    "    counter += 1\n",
    "box = sorted(box.items(), key=lambda x: x[1])\n",
    "    \n",
    "interact(create_bubbles, Topic=box);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print topics<a id='print_topics'></a>\n",
    "\n",
    "Print the ten most typicals words for each topic.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load dictionary\n",
    "dictionary = corpora.Dictionary.load(os.path.join(result_path, project + \".dict\"))\n",
    "    \n",
    "topics = model.show_topics(num_topics=100, num_words=50, log=False, formatted=True)\n",
    "counter = 5\n",
    "for topic in sorted(topics, key=itemgetter(0)):\n",
    "    print (list(table)[counter], \":\\n\", topic[1], \"\\n\")\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 5,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "***\n",
    "## Topic development over time\n",
    "<a id='stats_per_topic'></a>\n",
    "\n",
    "Select topics to view their development over time for the whole corpus. You may select multiple topics with the CTRL key.\n",
    "\n",
    "[Back to top](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "selected = [list(table)[45], list(table)[42]] \n",
    "interact(topic_stats, Topics= widgets.SelectMultiple(options=list(table)[5:], value=selected));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 9,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Top ten topics for a blog / a profile<a id='stats_per_blog'></a>\n",
    "\n",
    "Select a blog/social media profile in the dropdown box. The naming convention is as follows: subcorpus:author:alias, e.g. everyday:goralik:zz_snorapp.\n",
    "\n",
    "[Back to top](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(10,6)\n",
    "def create_bars(Subcorpus):\n",
    "    sub, top_topics = corpus_stats(Subcorpus)\n",
    "    del top_topics['words']\n",
    "    top_topics.sort_values(ascending=False, inplace=True)\n",
    "    top_topics = top_topics.head(10)\n",
    "    if Subcorpus == \"\":\n",
    "        Subcorpus = \"All\"\n",
    "    top_topics.plot(kind='bar', title=Subcorpus)\n",
    "    plt.savefig(Subcorpus+\"_topics.png\")\n",
    "    plt.show()\n",
    "\n",
    "interact(create_bars, Subcorpus=names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Show data table for corpus / subcorpus / blog or profile<a id='data'></a>\n",
    "Select a blog/social media profile in the dropdown box. The naming convention is as follows: subcorpus:author:alias, e.g. everyday:goralik:zz_snorapp.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(table, grid_options={'fullWidthRows': True, 'explicitInitialisation':True, 'asyncEditorLoading': True, 'enableTextSelectionOnCells': True, 'syncColumnCellResize':True, 'enableColumnReorder':False,'forceFitColumns': False, 'defaultColumnWidth': 80, 'enableCellNavigation': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
